{"cells":[{"cell_type":"code","source":["import pyspark.sql as ps\nimport pyspark.sql.types as pst\nimport pyspark\n\n\ndef as_list(input_df:ps.DataFrame, deep=False, order_by=None):\n    \"\"\"Convert Spark DataFrame to Python list of dictionaries.\n    \n    The DataFrame is collected and each row is converted into\n    a dictionary. Optionally fields of pyspark Row type are \n    also recursively converted to dictionary.\n    \n    The resulting list could be sorted, using a supplied key function.\n    Sorted list is useful, for example, to compare against expcted \n    fixture.\n    \n    Parameters:\n      input_df (pyspark.sql.DataFrame): Spark DataFrame to be converted.\n      \n      deep (bool): (Default=False) Whether Row to dictionary conversion should be deep.\n      \n      order_by (callable): (Default=None) Key function to order by. If provided, the result \n                           list will be sorted using the provided key function.\n    \"\"\"\n    def row_as_dict(r):\n      d = r.asDict()\n      if deep:\n        for k in d:\n          if isinstance(d[k], pst.Row):\n            d[k] = row_as_dict(d[k])\n      return d\n    \n    if order_by:\n      assert callable(order_by), \"order_by must be callable\"\n    if isinstance(input_df, ps.DataFrame):\n        result = [row_as_dict(r) for r in input_df.collect()]\n    else:\n        result = input_df\n    if order_by and isinstance(result, list):\n        result.sort(key=order_by)\n    return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"pyspark_lib","notebookId":4274223463284111},"nbformat":4,"nbformat_minor":0}
